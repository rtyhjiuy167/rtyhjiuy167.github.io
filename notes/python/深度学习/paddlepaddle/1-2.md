---
title: 1-2 
top: 1.2
tags:
  - paddlepaddle
categories:
  - paddlepaddle
---

```python
import numpy as np
import matplotlib.pyplot as plt

# y = x^2
def func(x):
    return np.square(x)

# y'= 2x
def dfunc(x):
    return 2*x

def gradient_descent(x_start,func_deri,epochs,learning_rate):
    """
    args:
    	x_start: x 的起始点
    	func_deri: 目标函数的一阶导函数
    	epochs: 迭代周期
    	learning_rate: 学习率
    """
    theta_x=np.zeros(epochs+1)
    temp_x=x_start
    theta_x[0]=temp_x
    for i in range(epochs):
        deri_x=func_deri(temp_x)
        delta=-deri_x *learning_rate
        temp_x=temp_x+delta
        theta_x[i+1]=temp_x
    return theta_x

def mat_plot():
    line_x=np.linspace(-5,5,100)
    line_y=func(line_x)
    x_start = -5
    epochs=5
    lr=0.3
    x=gradient_descent(x_start,dfunc,epochs,lr)

    color='r'
    plt.plot(line_x,line_y,c='b')
    plt.plot(x,func(x),c=color,label='lr={}'.format(lr))
    plt.scatter(x,func(x),c=color)
    plt.legend()
    plt.show()
mat_plot()
```