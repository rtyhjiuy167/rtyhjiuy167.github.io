---
title: 12-4 百度图片
top: 12.4
tags:
  - python
categories:
  - python
---

```python
import os.path

import requests

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:92.0) Gecko/20100101 Firefox/92.0'
}


def getPages(kw, num):
    global headers
    params = []
    for i in range(30, 30 * num + 30, 30):
        params.append({'tn': 'resultjson_com',
                       'logid': '7659923891283134928',
                       'ipn': 'rj',
                       'ct': '201326592',
                       'is': '',
                       'fp': 'result',
                       'queryWord': kw,
                       'cl': '2',
                       'lm': '-1',
                       'ie': 'utf-8',
                       'oe': 'utf-8',
                       'adpicid': '',
                       'st': '-1',
                       'z': '',
                       'ic': '',
                       'hd': '',
                       'latest': '',
                       'copyrigh': '',
                       'word': kw,
                       's': '',
                       'se': '',
                       'tab': '',
                       'width': '',
                       'height': '',
                       'face': '0',
                       'istype': '2',
                       'qc': '',
                       'nc': '1',
                       'fr': '',
                       'expermode': '',
                       'nojc': '',
                       'pn': i,
                       'rn': '30',
                       'gsm': '3c',
                       '1575710003840': '',
                       })
    url = 'https://image.baidu.com/search/acjson'
    urls = []
    for i in params:
        res = requests.get(url, params=i, headers=headers).json()['data']
        urls.append(res)
    return urls


def downloading(datalist, dir):
    num = 0
    global headers
    if not os.path.exists(dir):
        os.mkdir(dir)
    for data in datalist:
        for i in data:
            url_image = i.get("thumbURL")
            if url_image != None:
                images = requests.get(url=url_image)
                print(i.get("fromPageTitleEnc"))
                open(f'./{dir}/{num}.jpg', 'wb').write(images.content)
                num += 1


keyword = input('请输入搜索图片的关键字：')
datalist = getPages(keyword, 2)
downloading(datalist, 'catch-picture')
```