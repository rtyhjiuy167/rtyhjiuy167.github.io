---
title: 17-2 决策树-回归树
top: 17.22
tags:
  - python
categories:
  - python
---

<h3>回归树</h3>

```python
from sklearn.datasets import load_boston  # 波斯顿房价集 该数据集的标签(target)是连续的数字
from sklearn.model_selection import cross_val_score  # 导入交叉验证需要的模块
from sklearn.tree import DecisionTreeRegressor  # 导入回归树需要的模块 连续的数字不能用分类树了
boston = load_boston()
# 实例化
regressor = DecisionTreeRegressor(random_state=0)
# 交叉验证
# 第一个参数：实例化好的模型
# 第二个参数：完整的数据的特征矩阵
# 第三个参数：数据的标签
# cv参数：交叉验证次数 这里是把数据分为10份，每次用九份作训练集，剩下的一份作测试集 进行10次 默认为5
# scoring
v = cross_val_score(regressor, boston.data, boston.target, cv=10, scoring="neg_mean_squared_error")
"""
回归树衡量分枝质量的指标，支持的标准有三种
    "mse"   使用均方误差 mean squared error
    "friedman_mse"  使用费尔德曼均方误差
    "mae"   使用绝对平均误差 mean absolute error
    "neg_mean_squared_error" 负均方误差 误差被sklearn划分为模型的一种损失，所以都以负数表示
    回归树的接口score返回的是R平方  R^2 = 1 - 残差平方和/总平方和 R平方可正可负 均方误差永为正数
"""
print(v)
```

<h4>用回归树拟合正弦曲线</h3>

<h5>测试集</h5>

```python
import numpy as np
import matplotlib.pyplot as plt

# 创造一条含有噪声的正弦曲线 作为训练集
rng = np.random.RandomState(1)  # 随机数种子
x = np.sort(5 * np.random.rand(80, 1), axis=0)  # rng.rand(80, 1) 按照数种子生成随机数 二维  生成是乱序的 需要sort排序一下
y = np.sin(x).ravel()  # 视图上降维
y[::5] += 3 * (0.5 - rng.rand(16))  # 现实中的数据不可能很完美，需要自己增加噪声 这里每5个加上随机数 0~1 中值是0.5,所以用0.5去减，得到-0.5~0.5 范围小，所以乘一下
plt.figure()
plt.scatter(x, y, edgecolors="black", color="darkorange", label="data")
plt.show()
```

<h5>测试集</h5>

```python
import numpy as np

x_test = np.arange(0, 5.0, 0.01)[:, np.newaxis]
print(x_test)
```

<h5>完整代码</h5>

```python
from sklearn.tree import DecisionTreeRegressor
import numpy as np
import matplotlib.pyplot as plt

# 训练集
rng = np.random.RandomState(1)
x = np.sort(5 * np.random.rand(80, 1), axis=0)
y = np.sin(x).ravel()
y[::5] += 3 * (0.5 - rng.rand(16))

# 实例化两个模型
regr_1 = DecisionTreeRegressor(max_depth=2)
regr_2 = DecisionTreeRegressor(max_depth=5)

# 训练模型
regr_1.fit(x, y)
regr_2.fit(x, y)

# 自己生成测试集
x_test = np.arange(0, 5.0, 0.01)[:, np.newaxis]

# 调用回归树的接口 测试
# 得到每个测试样本点的回归或者分类的结果
y_1 = regr_1.predict(x_test)
y_2 = regr_2.predict(x_test)

plt.figure()
plt.scatter(x, y, s=20, edgecolors="black", c="darkorange", label="data")
plt.plot(x_test, y_1, color="cornflowerblue", label="max_deph=2", linewidth=2)
plt.plot(x_test, y_2, color="yellowgreen", label="max_deph=5", linewidth=2)
plt.xlabel("data")
plt.ylabel("target")
plt.title("Decision Tree Regression")
plt.legend()
plt.show()
```
