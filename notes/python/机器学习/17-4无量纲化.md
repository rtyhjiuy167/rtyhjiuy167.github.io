---
title: 17-4 无量纲化
top: 17.4
tags:
  - python
categories:
  - python
---

<h4>归一化</h4>

1.使用sklearn来实现数据归一化

```python
from sklearn.preprocessing import MinMaxScaler  # 导入归一化所需的模块

data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]

# 实现归一化
scaler = MinMaxScaler()  # 实例化
scaler = scaler.fit(data)  # fit，在这里本质是生成min(x)和max(x)

result = scaler.transform(data)  # 通过接口导出结果
print(result)
# [[0.   0.  ]
#  [0.25 0.25]
#  [0.5  0.5 ]
#  [1.   1.  ]]

# fit_transform == fit + transform
result_ = scaler.fit_transform(data)  # 训练和导出结果一步达成
print(result_)
# [[0.   0.  ]
#  [0.25 0.25]
#  [0.5  0.5 ]
#  [1.   1.  ]]


# inverse_transform 可以把归一化的结果逆转
data_ = scaler.inverse_transform(result)
print(data_)
# [[-1.   2. ]
#  [-0.5  6. ]
#  [ 0.  10. ]
#  [ 1.  18. ]]

# 使用MinMaxScaler的参数feature_range可实现将数据归一化到[0,1]以外的范围中
data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
scaler = MinMaxScaler(feature_range=[5, 10])  # 依然实例化

result = scaler.fit_transform(data)
print(result)
# [[ 5.    5.  ]
#  [ 6.25  6.25]
#  [ 7.5   7.5 ]
#  [10.   10.  ]]

#   当X中的特征数量非常多的时候，fit会报错并表示，数据量太大了我计算不了
# 此时使用partial_fit作为训练接口
# scaler = scaler.partial_fit(data)
```

1.自己使用numpy来实现数据归一化

```python
import numpy as np

X = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])
# 归一化 (X - min(x) ) / ( max(x) - min(x) )
X_nor = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))
print(X_nor)
# [[0.   0.  ]
#  [0.25 0.25]
#  [0.5  0.5 ]
#  [1.   1.  ]]

# 逆转归一化
X_returned = X_nor * (X.max(axis=0) - X.min(axis=0)) + X.min(axis=0)
print(X_returned)
# [[-1.   2. ]
#  [-0.5  6. ]
#  [ 0.  10. ]
#  [ 1.  18. ]]
```

MinMaxScaler对异常值非常敏感<br>在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像 处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中

<h4>标准化</h4>

数据标准化(Standardization，又称Z-score normalization)

```python
from sklearn.preprocessing import StandardScaler

data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
scaler = StandardScaler()  # 实例化
scaler.fit(data)  # fit，本质是生成均值和方差

print(scaler.mean_)  # 查看均值的属性mean_
# [-0.125  9.   ]

print(scaler.var_)  # 查看方差的属性var_
# [ 0.546875 35.      ]

x_std = scaler.transform(data)  # 通过接口导出结果
print(x_std)
# [[-1.18321596 -1.18321596]
#  [-0.50709255 -0.50709255]
#  [ 0.16903085  0.16903085]
#  [ 1.52127766  1.52127766]]


# 导出的结果是一个数组，用mean()查看均值
print(x_std.mean())  # 0.0

# 用std()查看标准差
x_std.std()
print(x_std.std())  # 1.0

# 使用fit_transform(data)一步达成结果
scaler.fit_transform(data)
# 使用inverse_transform逆转标准化
scaler.inverse_transform(x_std)
```

在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择

