---
title: 17-5 数据处理
top: 17.5
tags:
  - python
categories:
  - python
---

为了让数据适应算法和库，我们必须将数据进行编码，即是说，将文字型数据转换为数值型

<h4>修改标签</h4>

```python
import pandas as pd
from sklearn.preprocessing import LabelEncoder  # 标签专用，能够将分类转换为分类数值

d1 = [{"name": "XiaoMing", "age": 18, "gender": "male", "hobby": "running"},
      {"name": "ZhangSan", "age": 21, "gender": "male", "hobby": "playing basketball"},
      {"name": "XiaoHong", "age": 21, "gender": "female", "hobby": "swimming"}]
data1 = pd.DataFrame(d1)
print(data1)
#        name  age  gender               hobby
# 0  XiaoMing   18    male             running
# 1  ZhangSan   21    male  playing basketball
# 2  XiaoHong   21  female            swimming

# 得到标签那一列 允许一维
y = data1.iloc[:, -1]

# 实例化
le = LabelEncoder()

# 导入数据
le = le.fit(y)

# 导入数据后，用 transform 接口调取结果
label = le.transform(y)
print(label)  # [1 0 2]

# 用transform 接口调取的结果，可以逆转
print(le.inverse_transform(label))  # ['running' 'playing basketball' 'swimming']

# 导入数据后，可用 .classes_ 查看标签中有多少类别
print(le.classes_)  # ['playing basketball' 'running' 'swimming']

# 让已改的标签赋给原标签
data1.iloc[:, -1] = label
print(data1.head())
#        name  age  gender  hobby
# 0  XiaoMing   18    male      1
# 1  ZhangSan   21    male      0
# 2  XiaoHong   21  female      2

# 实际上标签转换在导包后只需要一行代码
# data1.iloc[:, -1] = LabelEncoder().fit_transform(data1.iloc[:, -1])

```

<h4>修改特征矩阵</h4>

```python
import pandas as pd
from sklearn.preprocessing import OrdinalEncoder  
# 特征专用，能够将分类特征转换为分类数值 只用于修改有序变量

d1 = [{"name": "XiaoMing", "age": 18, "gender": "male", "hobby": "running"},
      {"name": "ZhangSan", "age": 21, "gender": "male", "hobby": "playing basketball"},
      {"name": "XiaoHong", "age": 21, "gender": "female", "hobby": "swimming"}]
data1 = pd.DataFrame(d1)
print(data1)
#        name  age  gender               hobby
# 0  XiaoMing   18    male             running
# 1  ZhangSan   21    male  playing basketball
# 2  XiaoHong   21  female            swimming

# 必须二维
y = data1.iloc[:, 1:-1] # 修改第二列（即age所在列）至倒数第一列（不包括倒数第一列）

# 实例化
le = OrdinalEncoder()

# 导入数据
le = le.fit(y)

# 导入数据后，用 transform 接口调取结果
feature = le.transform(y)
print(feature)
# [[0. 1.]
#  [1. 1.]
#  [1. 0.]]

# 用transform 接口调取的结果，可以逆转
print(le.inverse_transform(feature))  # ['running' 'playing basketball' 'swimming']
# [[18 'male']
#  [21 'male']
#  [21 'female']]

# 导入数据后，可用 .classes_ 查看标签中有多少类别
print(le.categories_)  # [array([18, 21], dtype=int64), array(['female', 'male'], dtype=object)]

# 让已改的标签赋给原标签
data1.iloc[:, 1:-1] = feature
print(data1.head())
#        name  age  gender               hobby
# 0  XiaoMing  0.0     1.0             running
# 1  ZhangSan  1.0     1.0  playing basketball
# 2  XiaoHong  1.0     0.0            swimming

# 其实gender是名义变量，应该是“有你没我”的关系，不能单纯1，0表示,应该[1,0] [0,1] 表示


# 实际上标签转换在导包后只需要一行代码
# data1.iloc[:, 1:-1] = OrdinalEncoder().fit_transform(data1.iloc[:, 1:-1])
```

我们来思考三种不同性质的分类数据： 

1） 舱门（A，B，C） 三种取值A，B，C是相互独立的，彼此之间完全没有联系，表达的是A≠B≠C的概念。这是名义变量<br>2） 学历（小学，初中，高中） 三种取值不是完全独立的，我们可以明显看出，在性质上可以有高中>初中>小学这样的联系，学历有高低，但是学 历取值之间却不是可以计算的，我们不能说小学 + 某个取值 = 初中。这是有序变量<br>3） 体重（>45kg，>90kg，>135kg） 各个取值之间有联系，且是可以互相计算的，比如120kg - 45kg = 90kg，分类之间可以通过数学计算互相转换。这是有距变量

类别OrdinalEncoder可以用来处理有序变量，但对于名义变量，我们只有使用哑变量的方式来处理，告诉算法这是不可计算的，只有这样才能够向算法传达最准确的信息

创建哑变量可以用OneHotEncoder（处理分类型），也可以用KBinsDiscretizer（处理连续型）

```python
import pandas as pd
from sklearn.preprocessing import OneHotEncoder  # 独热编码，创建哑变量

d = [{"Age": 15, "Gender": "male", "Embarked": "A", "Survived": 1},
     {"Age": 23, "Gender": "male", "Embarked": "B", "Survived": 1},
     {"Age": 31, "Gender": "female", "Embarked": "C", "Survived": 0},
     {"Age": 21, "Gender": "female", "Embarked": "A", "Survived": 0}]
data = pd.DataFrame(d)
print(data)
#    Age  Gender Embarked  Survived
# 0   15    male        A         1
# 1   23    male        B         1
# 2   31  female        C         0
# 3   21  female        A         0

# 必须二维(即两个特征或一个特征但须升维)
X = data.iloc[:, 1:-1]  # X 为要修改成哑变量的 特征所在列
print(X)
#    Gender Embarked
# 0    male        A
# 1    male        B
# 2  female        C
# 3  female        A
enc = OneHotEncoder(categories='auto').fit(X)
result = enc.transform(X).toarray()
print(result)
# [[0. 1. 1. 0. 0.]
#  [0. 1. 0. 1. 0.]
#  [1. 0. 0. 0. 1.]
#  [1. 0. 1. 0. 0.]]

# 上面三步依然可以直接一步到位
# OneHotEncoder(categories='auto').fit_transform(X).toarray()

# 可以还原
print(pd.DataFrame(enc.inverse_transform(result)))
#         0  1
# 0    male  A
# 1    male  B
# 2  female  C
# 3  female  A

# 把转换成哑巴量的特征，先拼接到原 DataFrame 中
newdata = pd.concat([data, pd.DataFrame(result)], axis=1)
print(newdata.head())
#    Age  Gender Embarked  Survived    0    1    2    3    4
# 0   15    male        A         1  0.0  1.0  1.0  0.0  0.0
# 1   23    male        B         1  0.0  1.0  0.0  1.0  0.0
# 2   31  female        C         0  1.0  0.0  0.0  0.0  1.0
# 3   21  female        A         0  1.0  0.0  1.0  0.0  0.0

# 已经替换成哑变量了，那原特征就不需要了
# inplace=True 替换原DataFrame
newdata.drop(["Gender", "Embarked"], axis=1, inplace=True)
print(newdata)
#    Age  Survived    0    1    2    3    4
# 0   15         1  0.0  1.0  1.0  0.0  0.0
# 1   23         1  0.0  1.0  0.0  1.0  0.0
# 2   31         0  1.0  0.0  0.0  0.0  1.0
# 3   21         0  1.0  0.0  1.0  0.0  0.0

# 导入数据后，可以使用 get_feature_names_out() 查看转换后的特征
print(enc.get_feature_names_out())  # ['Gender_female' 'Gender_male' 'Embarked_A' 'Embarked_B' 'Embarked_C']

# 修改转换后的默认列索引
newdata.columns = ["Age", "Survived", "Female", "Male", "Embarked_A", "Embarked_B", "Embarked_C"]
print(newdata)
#    Age  Survived  Female  Male  Embarked_A  Embarked_B  Embarked_C
# 0   15         1     0.0   1.0         1.0         0.0         0.0
# 1   23         1     0.0   1.0         0.0         1.0         0.0
# 2   31         0     1.0   0.0         0.0         0.0         1.0
# 3   21         0     1.0   0.0         1.0         0.0         0.0
```

标签是一般不用做哑变量处理，但如果填补缺失值时，可能需要...

<h4>二值化</h4>

二值化是对文本计数数据的常见操作，分析人员 可以决定仅考虑某种现象的存在与否

```python
import pandas as pd
from sklearn.preprocessing import Binarizer

d = [{"Age": 15, "Gender": "male", "Embarked": "A", "Survived": 1},
     {"Age": 23, "Gender": "male", "Embarked": "B", "Survived": 1},
     {"Age": 31, "Gender": "female", "Embarked": "C", "Survived": 0},
     {"Age": 21, "Gender": "female", "Embarked": "A", "Survived": 0}]
data = pd.DataFrame(d)
print(data)
#    Age  Gender Embarked  Survived
# 0   15    male        A         1
# 1   23    male        B         1
# 2   31  female        C         0
# 3   21  female        A         0

X = data.iloc[:, 0].values.reshape(-1, 1)

# threshold 阈值 默认为0
transformer = Binarizer(threshold=22).fit_transform(X)
print(transformer)
# [[0]
#  [1]
#  [1]
#  [0]]

data.iloc[:, 0] = transformer.ravel()

print(data)
#    Age  Gender Embarked  Survived
# 0    0    male        A         1
# 1    1    male        B         1
# 2    1  female        C         0
# 3    0  female        A         0
```

<h4>分段</h4>

`preprocessing.KBinsDiscretizer`将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码

```python
import pandas as pd
from sklearn.preprocessing import KBinsDiscretizer  # 这是将连续型变量划分为分类变量的类

"""
n_bins 每个特征中分箱的个数，默认5，一次会被运用到所有导入的特征
encode 
     默认“onehot” 做哑变量，之后返回一个稀疏矩阵，每一列是一个特征中的一个类别，含有该类别的样本表示为1，不含的表示为0
     “ordinal”：每个特征的每个箱都被编码为一个整数，返回每一列是一个特征，每个特征下含有不同整数编码的箱的矩阵
     "onehot-dense"：做哑变量，之后返回一个密集数组 不常用
strategy 
     默认"quantile" 表示等位分箱，即每个特征中的每个箱内的样本数量都相同 
     "uniform"：表示等宽分箱，即每个特征中的每个箱的最大值之间的差为 (特征.max() - 特征.min())/(n_bins) 
"""
d = [{"Age": 15, "Gender": "male", "Embarked": "A", "Survived": 1},
     {"Age": 23, "Gender": "male", "Embarked": "B", "Survived": 1},
     {"Age": 31, "Gender": "female", "Embarked": "C", "Survived": 0},
     {"Age": 21, "Gender": "female", "Embarked": "A", "Survived": 0},
     {"Age": 41, "Gender": "female", "Embarked": "C", "Survived": 0},
     {"Age": 34, "Gender": "male", "Embarked": "B", "Survived": 0},
     {"Age": 51, "Gender": "male", "Embarked": "A", "Survived": 0}]
data = pd.DataFrame(d)
print(data)
#    Age  Gender Embarked  Survived
# 0   15    male        A         1
# 1   23    male        B         1
# 2   31  female        C         0
# 3   21  female        A         0
X = data.iloc[:, 0].values.reshape(-1, 1)
est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')
print(est.fit_transform(X))
# [[0.]
#  [0.]
#  [1.]
#  [0.]
#  [2.]
#  [1.]
#  [2.]]

# 查看转换后分的箱：变成了一列中的三箱
print(set(est.fit_transform(X).ravel()))  # {0.0, 1.0, 2.0}

est = KBinsDiscretizer(n_bins=3, encode='onehot', strategy='uniform')
#查看转换后分的箱：变成了哑变量
print(est.fit_transform(X).toarray())
# [[1. 0. 0.]
#  [1. 0. 0.]
#  [0. 1. 0.]
#  [1. 0. 0.]
#  [0. 0. 1.]
#  [0. 1. 0.]
#  [0. 0. 1.]]


```