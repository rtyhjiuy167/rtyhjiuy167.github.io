---
title: 17-3 随机森林回归
top: 17.33
tags:
  - python
categories:
  - python
---

<h3>随机森林回归</h3>

<h5>自己模拟缺失</h5>

```python
from sklearn.datasets import load_boston
import numpy as np
import pandas as pd

boston = load_boston()

X_full, y_full = boston.data, boston.target

n_samples = X_full.shape[0]
print(n_samples)  # 506
n_features = X_full.shape[1]
print(n_features)  # 13

rng = np.random.RandomState(0)
missing_rate = 0.5

# np.floor 向下取整 因为*小数，得到的可能也是小数，数据量应是整数
# np.floor 返回的是浮点数，需要int转换
n_missing_samples = int(np.floor(n_samples * n_features * missing_rate))
print(n_missing_samples)  # 3289

# 我们现在采样了3289个数据，远远超过我们的样本量506，所以我们使用随机抽取的函数randint。但如果我们需要
# 的数据量小于我们的样本量506，那我们可以采用np.random.choice来抽样，choice会随机抽取不重复的随机数，
# 因此可以帮助我们让数据更加分散，确保数据不会集中在一些行中
# missing_samples = rng.choice(dataset.data.shape[0],n_missing_samples,replace=False)


# 随机缺失某条数据某个特征 共缺失  n_missing_samples 个
# 而缺失值是需要行索引和列索引的
missing_features = rng.randint(0, n_features, n_missing_samples)  # 列索引
missing_samples = rng.randint(0, n_samples, n_missing_samples)  # 行索引

# numpy 的 copy() 是深拷贝
X_missing = X_full.copy()
y_missing = y_full.copy()

# 对二维数组 传入两个一一对应一维数组 可一次得到
X_missing[missing_samples, missing_features] = np.nan
X_missing = pd.DataFrame(X_missing)
# 转换成DataFrame是为了后续方便各种操作，numpy对矩阵的运算速度快到拯救人生，但是在索引等功能上却不如pandas来得好用
```

<h5>用0、平均数、随机森林填补数据</h5>

```python
from sklearn.datasets import load_boston
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
import numpy as np
import pandas as pd

boston = load_boston()

X_full, y_full = boston.data, boston.target

n_samples = X_full.shape[0]
n_features = X_full.shape[1]

rng = np.random.RandomState(0)
missing_rate = 0.5

n_missing_samples = int(np.floor(n_samples * n_features * missing_rate))

# 得到缺失值的行索引和列索引
missing_features = rng.randint(0, n_features, n_missing_samples)  # 列索引
missing_samples = rng.randint(0, n_samples, n_missing_samples)  # 行索引

# 深拷贝
X_missing = X_full.copy()
y_missing = y_full.copy()

X_missing[missing_samples, missing_features] = np.nan
X_missing = pd.DataFrame(X_missing)
# 转换成DataFrame是为了后续方便各种操作


# 使用均值进行填补
"""
missing_values 待填补的原值
strategy 填补方法
fill_value 填补值
"""
# 用均值填补
imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')
X_missing_mean = imp_mean.fit_transform(X_missing)
# 训练fit+导出predict -> 特殊接口 fit_transform
print(X_missing_mean)

# X_missing_mean是 numpy.adarray 而 isnull 只能用在 DataFrame 里
print(pd.DataFrame(X_missing_mean).isnull().sum())  # 看看每列的缺失值是否补全，全，则必为0

# 使用0进行填补
imp_0 = SimpleImputer(missing_values=np.nan, strategy="constant", fill_value=0)
X_missing_0 = imp_0.fit_transform(X_missing)
print(pd.DataFrame(X_missing_mean))

# 用随机森林填补
# 深拷贝带有缺失值的 DataFrame
X_missing_reg = X_missing.copy()

# 找出数据集中，缺失值从小到大排列的顺序
# np.argsort 返回缺失值的数目从小到大排序所对应的索引 np.sort 返回缺失值从小到大排序所对应的缺失值的数目
sortindex = np.argsort(X_missing_reg.isnull().sum(axis=0)).values
print(sortindex)

for i in sortindex:
    # 构建我们的新特征矩阵（即没有被选中去填充的特征+原始标签）和新标签(即被选中去填充的特征)
    df = X_missing_reg  # 浅拷贝 因为每循环都会填表
    fillc = df.iloc[:, i]  # 新标签(即被选中去填充的特征)

    # 将没有被选中去填充的特征切出来，并与原始标签所在列拼接
    df = pd.concat([df.iloc[:, df.columns != i], pd.DataFrame(y_full)], axis=1)

    # 在新特征矩阵中，对含有缺失值的列，进行0的填补
    df_0 = SimpleImputer(missing_values=np.nan,
                         strategy='constant', fill_value=0).fit_transform(df)

    # 找出我们的训练集和测试集

    # fillc是新标签(即被选中去填充的特征)
    # 我们需要的不是值，而是索引
    Ytrain = fillc[fillc.notnull()]  # 从新标签中找到不用填充的
    Ytest = fillc[fillc.isnull()]  # 从新标签中找到要填充的 即现在是空值

    # df_0是新特征矩阵
    Xtrain = df_0[Ytrain.index, :]  # 从中选出新标签为非空值的记录（数据）
    Xtest = df_0[Ytest.index, :]  # 从中选出新标签为空值的记录（数据），之后填补
    rfc = RandomForestRegressor(n_estimators=100)

    # 将新标签不为空的数据拿来训练
    rfc = rfc.fit(Xtrain, Ytrain)

    # 将新标签为空的数据拿来预测，以用来填补
    Ypredict = rfc.predict(Xtest)

    # 填补数据
    X_missing_reg.loc[X_missing_reg.iloc[:, i].isnull(), i] = Ypredict
```

<h5>对比不同填补方法的结果</h5>

```python
from sklearn.datasets import load_boston
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.impute import SimpleImputer
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

boston = load_boston()

X_full, y_full = boston.data, boston.target

n_samples = X_full.shape[0]
n_features = X_full.shape[1]

rng = np.random.RandomState(0)
missing_rate = 0.5

n_missing_samples = int(np.floor(n_samples * n_features * missing_rate))

# 得到缺失值的行索引和列索引
missing_features = rng.randint(0, n_features, n_missing_samples)  # 列索引
missing_samples = rng.randint(0, n_samples, n_missing_samples)  # 行索引

# 深拷贝
X_missing = X_full.copy()
y_missing = y_full.copy()

X_missing[missing_samples, missing_features] = np.nan
X_missing = pd.DataFrame(X_missing)
# 转换成DataFrame是为了后续方便各种操作

# 用均值填补
imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')
X_missing_mean = imp_mean.fit_transform(X_missing)

# 使用0进行填补
imp_0 = SimpleImputer(missing_values=np.nan, strategy="constant", fill_value=0)
X_missing_0 = imp_0.fit_transform(X_missing)

# 用随机森林填补
X_missing_reg = X_missing.copy()

sortindex = np.argsort(X_missing_reg.isnull().sum(axis=0)).values

for i in sortindex:
    # 构建我们的新特征矩阵（即没有被选中去填充的特征+原始标签）和新标签(即被选中去填充的特征)
    df = X_missing_reg  # 浅拷贝 因为每循环都会填表
    fillc = df.iloc[:, i]  # 新标签(即被选中去填充的特征)

    # 将没有被选中去填充的特征切出来，并与原始标签所在列拼接
    df = pd.concat([df.iloc[:, df.columns != i], pd.DataFrame(y_full)], axis=1)

    # 在新特征矩阵中，对含有缺失值的列，进行0的填补
    df_0 = SimpleImputer(missing_values=np.nan,
                         strategy='constant', fill_value=0).fit_transform(df)

    # 找出我们的训练集和测试集
    Ytrain = fillc[fillc.notnull()]  # 从新标签中找到不用填充的
    Ytest = fillc[fillc.isnull()]  # 从新标签中找到要填充的 即现在是空值

    Xtrain = df_0[Ytrain.index, :]  # 从中选出新标签为非空值的记录（数据）
    Xtest = df_0[Ytest.index, :]  # 从中选出新标签为空值的记录（数据），之后填补
    rfc = RandomForestRegressor(n_estimators=100)

    # 将新标签不为空的数据拿来训练
    rfc = rfc.fit(Xtrain, Ytrain)

    # 将新标签为空的数据拿来预测，以用来填补
    Ypredict = rfc.predict(Xtest)

    # 填补数据
    X_missing_reg.loc[X_missing_reg.iloc[:, i].isnull(), i] = Ypredict

# 对以不同的方式填补的四种数据进行打分
X = [X_full, X_missing_mean, X_missing_0, X_missing_reg]
mse = []  # 每个的结果放到该列表 mse越接近0越好
std = []
for x in X:
    estimator = RandomForestRegressor(random_state=0, n_estimators=100)
    scores = cross_val_score(estimator, x, y_full, scoring='neg_mean_squared_error',
                             cv=5).mean()
    mse.append(scores * -1)

x_labels = ['Full data',
            'Zero Imputation',
            'Mean Imputation',
            'Regressor Imputation']

colors = ['red', 'green', 'blue', 'orange']
print(mse)

plt.figure(figsize=(14, 6))  # 画出画布
ax = plt.subplot(111)  # 添加子图 如果有多个图表，则可以画多个子图

for i in np.arange(len(mse)):
    ax.barh(i, mse[i], color=colors[i], alpha=0.6, align='center')
ax.set_title('Imputation Techniques with Boston Data')
ax.set_xlim(left=np.min(mse) * 0.9,
            right=np.max(mse) * 1.1)

ax.set_yticks(np.arange(len(mse)))
ax.set_xlabel('MSE')
ax.set_yticklabels(x_labels)
plt.show()
# 发现用回归森林填补远比用0或平均填补要好
# 发现用回归森林的测试结果比原数据的还好，这有过拟合的可能
```