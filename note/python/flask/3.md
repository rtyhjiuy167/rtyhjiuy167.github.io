### flask搭建后端(使用队列与线程保持与服务对象连续通信)

```python
from flask import Flask
from flask import jsonify
from flask import request
import json
import threading
from multiprocessing import Queue

# 实例化
app = Flask(__name__)
list = []
lock = threading.Lock()
service_max = 1	# 限制最大的连接数

# 为每个连接的用户建立线程，同时为每个线程与服务端的建立两个队列用于保持通信
main2thread_queue = [Queue(5),Queue(5),Queue(5),Queue(5),Queue(5)]
thread2main_queue = [Queue(5),Queue(5),Queue(5),Queue(5),Queue(5)]

#测试用的 get 方法
@app.route("/")
def hello():
    return "Hello, World!"

#测试用的 get 方法
@app.route("/get_test", methods=['GET'])
def get_test():
    return jsonify({"get_test": "测试"})

# 每个连接的所创建的线程服务
def one_service(**kargcs):
    data_userID = kargcs["data_userID"]
    print(data_userID)
    m2t_q = main2thread_queue[list.index(data_userID)]
    t2m_q = thread2main_queue[list.index(data_userID)]
    # 测试用的num
    num_test = 0
    while(True):
        texts=m2t_q.get()
        print(texts)
        num_test=num_test+1
        t2m_q.put(num_test)



@app.route("/post_test", methods=['POST'])
def post_test():
    """
    当 status 为 001 时，表示服务已满
    :return:
    """
    if request.method == 'POST':
        data = request.get_data()
        data = json.loads(data)
        print(data)
        print(list)
        data_userID = data["userID"]
        data_texts = data["texts"]


        if data_userID in list:
            m2t_q = main2thread_queue[list.index(data_userID)]
            m2t_q.put(data_texts)
            t2m_q = thread2main_queue[list.index(data_userID)]
            res = t2m_q.get(data_texts)
            return jsonify({"post_test": "测试", "msg": "欢迎回来", "status": "000", "results": res})
        else:
            lock.acquire()
            if(len(list) < service_max):
                list.append(data_userID)
                lock.release()
                m2t_q = main2thread_queue[list.index(data_userID)]
                m2t_q.put(data_texts)
                print("创建threading")
                t = threading.Thread(target=one_service, kwargs={"data_userID": data_userID, "data_texts": data_texts})
                t.start()
                t2m_q = thread2main_queue[list.index(data_userID)]
                print("等待")
                res=t2m_q.get(data_texts)

                return jsonify({"post_test": "测试", "msg": "添加成功", "status": "000", "results": res})
            else:
                lock.release()
                return jsonify({"post_test": "测试", "msg": "服务已满", "status": "001", "results": data})

if __name__ == '__main__':
    app.run(debug=False, host='127.0.0.1', port='8080') # 服务器部署时，host填写 0.0.0.0 则允许外网通过IP地址访问
```

测试post接口的代码：

```python
import requests
import json

text = "你好。"
data = {"texts": text, "userID": "1234567"}

url = "http://192.168.1.103:8080/emotion_test"
headers = {"Content-Type": "application/json"}
r = requests.post(url=url, headers=headers, data=json.dumps(data))
if r:
    print(r.json())
```

### 使用flask调用plato模型实现连续对话

```python
from flask import Flask
from flask import jsonify
from flask import request
import json
import threading
from multiprocessing import Queue
import paddlehub as hub

app = Flask(__name__)
list = []
lock = threading.Lock()
service_max = 1
main2thread_queue = [Queue(5)]
thread2main_queue = [Queue(5)]

model = hub.Module(name='plato-mini') # 放在外面，提前进行加载 #仅允许加载一次,不然内存不足


def one_service(model=model, **kargcs):
    data_userID = kargcs["data_userID"]
    m2t_q = main2thread_queue[list.index(data_userID)]
    t2m_q = thread2main_queue[list.index(data_userID)]
    with model.interactive_mode(max_turn=50):
        while True:
            try:
                texts = m2t_q.get(timeout=10)  # 限制为10秒,10秒无数据传入线程结束
                human_utterance = texts  # 传过来时，记得去首尾空格 传过来
                print(human_utterance)
                robot_utterance = model.predict(human_utterance)[0]
                t2m_q.put(robot_utterance)
                print("[Bot]: %s" % robot_utterance)
            except:
                list.remove(data_userID)
                break


@app.route("/post_test", methods=['POST'])
def post_test():
    """
    当 status 为 001 时，表示服务已满
    :return:
    """
    if request.method == 'POST':
        data = request.get_data()
        data = json.loads(data)
        data_userID = data["userID"]
        data_texts = data["texts"]

        if data_userID in list:
            m2t_q = main2thread_queue[list.index(data_userID)]
            m2t_q.put(data_texts)
            t2m_q = thread2main_queue[list.index(data_userID)]
            res = t2m_q.get(data_texts)
            return jsonify({"msg": "继续上次的会话", "status": "000", "results": res})
        else:
            lock.acquire()
            if len(list) < service_max:
                list.append(data_userID)  # 此处仅允许一个，所以不会报错
                lock.release()
                m2t_q = main2thread_queue[list.index(data_userID)]
                m2t_q.put(data_texts)
                t = threading.Thread(target=one_service,
                                     kwargs={"data_userID": data_userID, "data_texts": data_texts})
                t.start()
                t2m_q = thread2main_queue[list.index(data_userID)]
                res = t2m_q.get(data_texts)
                return jsonify({"msg": "成功", "status": "000", "results": res})
            else:
                lock.release()
                return jsonify({"msg": "服务已满", "status": "001", "results": data})


if __name__ == '__main__':
    app.run(debug=False, host='0.0.0.0', port='8080')

```

