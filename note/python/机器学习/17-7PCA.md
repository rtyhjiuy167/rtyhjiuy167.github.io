---
title: 17-7 PCA
top: 17.7
tags:
  - python
categories:
  - python
---

<h4>PCA</h4>

PCA，是将已存在的特征进行压缩，降维完毕后的特征不是原本的特征矩阵中的任何一个特征，而是通过某些方式组合起来的新特征。

通常来说，在新的特征矩阵生成之前，我们无法知晓PCA都建立了怎样的新特征向量，新特征矩阵生成之后也不具有可读性，我们无法判断新特征矩阵的特征是从原数据中的什么特征组合而 来，新特征虽然带有原始数据的信息，却已经不是原数据上代表着的含义了。

参数n_components：<br>1.整数，默认min(X.shape)<br>2.输入 mle 用最大似然估计(maximum likelihood estimation)自选超参数的方法 这方法用时较长<br>3.输入[0,1]之间的浮点数，并且让参数svd_solver =='full'，表示希望降维后的总解释性方差占比大于n_components 指定的百分比，即是说，希望保留百分之多少的信息量

```python
from sklearn.datasets import load_iris  # 鸢尾花数据集
from sklearn.decomposition import PCA
import numpy as np

iris = load_iris()
y = iris.target  # 标签
X = iris.data  # 特征矩阵
print(X.shape)  # (150, 4)

# 实例化 n_components是我们降维后需要的维度，即降维后需要保留的特征数量
pca = PCA(n_components=2)  # 降为2维
# 传入特征矩阵，拟合模型
pca = pca.fit(X)
# 传入特征矩阵，得到降维矩阵
X_dr = pca.transform(X)

# 可一步到位
# X_dr = PCA(2).fit_transform(X)

print(X_dr.shape)  # (150, 2)

# 取出特征为0 的数据
print(X_dr[y == 0])

# 取出标签为0（行中y==0），且为第一个特征的数据
# print(X_dr[y == 0, 0])
# 取出标签为0（行中y==0），且为第二个特征的数据
# print(X_dr[y == 0, 1])

# 属性 xplained_variance_ 查看降维后每个新特征向量上所带的信息量大小（可解释性方差的大小）
print(pca.explained_variance_)  # [4.22824171 0.24267075]

# 属性 explained_variance_ratio_ 查看降维后每个新特征向量所占的信息量占原始数据总信息量的百分比
print(pca.explained_variance_ratio_)  # [0.92461872 0.05306648]

# 可不输入n_components，默认为特征矩阵维数
# 在此情况下，explained_variance_ratio_ 可查看百分比
print(PCA().fit(X).explained_variance_ratio_)  # [0.92461872 0.05306648 0.01710261 0.00521218]

# np.cumsum() 实现累加
print(np.cumsum(PCA().fit(X).explained_variance_ratio_))  # [0.92461872 0.97768521 0.99478782 1.        ]
```

降维后选取每个标签的对应的特征值（只选了第一个）

```python
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

iris = load_iris()
y = iris.target  # 标签
X = iris.data  # 特征矩阵
pca = PCA(n_components=2)
pca = pca.fit(X)
X_dr = pca.transform(X) # 新特征，但不是降维后的特征矩阵！

plt.figure()  # 现在我要画图了，给我一个画布
plt.scatter(X_dr[y == 0, 0], X_dr[y == 0, 1], c="red", label=iris.target_names[0])
plt.scatter(X_dr[y == 1, 0], X_dr[y == 1, 1], c="black", label=iris.target_names[1])
plt.scatter(X_dr[y == 2, 0], X_dr[y == 2, 1], c="orange", label=iris.target_names[2])
plt.legend()
plt.title('PCA of IRIS dataset')
plt.show()
```

以PCA为代表的降维算法是 特征创造（feature creation，或feature construction）的一种

PCA一般不适用于探索特征和标签之间的关系的模型（如线性回归），因为无法解释的新特征和标签之间的关系

在线性回归模型中，应使用特征选择

```python
# 画出特征信息量的累加值
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

iris = load_iris()
X = iris.data  # 特征矩阵
pca_line = PCA().fit(X)
plt.plot([1, 2, 3, 4], np.cumsum(pca_line.explained_variance_ratio_))  # 传入的x为 1,2,3,4
plt.xticks([1, 2, 3, 4])  # 这是为了限制坐标轴显示为整数
plt.xlabel("number of components after dimension reduction")
plt.ylabel("cumulative explained variance ratio")
plt.show()
```

<h4>人脸识别</h4>

1.

```python
from sklearn.datasets import fetch_lfw_people  # 由7个人，共一千张照片组成的数据
import matplotlib.pyplot as plt

# 在数据集中，每个人取60张照片
# 实例化
faces = fetch_lfw_people(min_faces_per_person=60)

print(faces.data.shape)  # (1348, 2914)
"""
(1348, 2914)
行是样本
列是样本相关的所有特征
"""

print(faces.images.shape)  # (1348, 62, 47)
"""
(1348, 62, 47)
1348 是矩阵中图像的个数
62 是每个图形的特征矩阵的行
47 是每个图像的特征矩阵的列
相当于一张图是由62行和47列构造的一个平面（表）
"""

X = faces.data
# subplots
# 参数： 一个画布画不同的图 4行 5列（相当于20张图） 画布总大小 横纵坐标
fig, axes = plt.subplots(4, 5
                         , figsize=(8, 4)
                         , subplot_kw={"xticks": [], "yticks": []}  # 不要显示坐标轴
                         )

# fig 是画布
# axes 是由子图的对象组成的array
print(fig)  # Figure(800x400)
print(axes)
# [[<AxesSubplot:> <AxesSubplot:> <AxesSubplot:> <AxesSubplot:>
#   <AxesSubplot:>]
#  [<AxesSubplot:> <AxesSubplot:> <AxesSubplot:> <AxesSubplot:>
#   <AxesSubplot:>]
#  [<AxesSubplot:> <AxesSubplot:> <AxesSubplot:> <AxesSubplot:>
#   <AxesSubplot:>]
#  [<AxesSubplot:> <AxesSubplot:> <AxesSubplot:> <AxesSubplot:>
#   <AxesSubplot:>]]

# faces.images[0, :, :]表示 从实例化的faces对象中的images里取索引为0的图像，并取它的所有行与列
# imshow 用来填充画布 cmap 填充的颜色
print(axes[0][0].imshow(faces.images[0, :, :], cmap="gray"))  # AxesImage(100,285.043;106.897x66.9565)

plt.show()
```

2.用原特征矩阵画图

```python
from sklearn.datasets import fetch_lfw_people
import matplotlib.pyplot as plt

# 在数据集中，每个人取60张照片
# 实例化
faces = fetch_lfw_people(min_faces_per_person=60)

X = faces.data
# subplots
# 参数： 一个画布画不同的图 3行 8列（相当于24张图） 画布总大小 横纵坐标
fig, axes = plt.subplots(3, 8
                         , figsize=(8, 4)
                         , subplot_kw={"xticks": [], "yticks": []}  # 不要显示坐标轴
                         )

# 填充图像
for i, ax in enumerate(axes.flat):  # 二维不好一次填充，直接填充压缩的
    ax.imshow(faces.images[i, :, :]
              , cmap="gray"  # 选择色彩的模式
              )
plt.show()
```

3.用降维后得到的特征空间画图

```python
from sklearn.datasets import fetch_lfw_people  # 由7个人，共一千张照片组成的数据
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# 在数据集中，每个人取60张照片
# 实例化
faces = fetch_lfw_people(min_faces_per_person=60)

print(faces.data.shape)  # (1348, 2914)
print(faces.images.shape)  # (1348, 62, 47)

X = faces.data

# 原本有2914维，现在降到150维
pca = PCA(150).fit(X)
# pca.components_ 得到的是V(k,n)，是新特征空间 不是降维后的特征矩阵！
# 比如，对于2维特征矩阵，只用一个特征向量来描述这组数据，即将二维数据降为一维数据，并且尽可能地保留信息量
V = pca.components_
print(V.shape)  # (150, 2914) # 用150个新特征向量组成的2914维空间

print(V[0].shape)  # (2914,) 一维 # 之后要拆成 62, 47

# 用新特征空间画图
# 原本的图是 62行 47列的像素图，得到新特征空间后还需 reshape下 才能画
fig, axes = plt.subplots(3, 8, figsize=(8, 4), subplot_kw={"xticks": [], "yticks": []})
for i, ax in enumerate(axes.flat):
    ax.imshow(V[i, :].reshape(62, 47), cmap="gray")

plt.show()
```

3.用降维后得到的新特征矩阵画图

```python
from sklearn.datasets import fetch_lfw_people
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

# 在数据集中，每个人取60张照片
# 实例化
faces = fetch_lfw_people(min_faces_per_person=60)

X = faces.data
pca = PCA(150)
X_dr = pca.fit_transform(X)

# 将降维后矩阵用 inverse_transform 返回原空间 形成新特征矩阵
X_inverse = pca.inverse_transform(X_dr)
print(X_inverse.shape)  # (1348, 2914)
print(X_inverse[0].shape)  # (2914,)

fig, axes = plt.subplots(3, 8, figsize=(8, 4), subplot_kw={"xticks": [], "yticks": []})
for i, ax in enumerate(axes.flat):
    ax.imshow(X_inverse[i, :].reshape(62, 47), cmap="gray")

plt.show()
```

4.用降维后得到的新特征矩阵和原特征矩阵的对比图

```python
from sklearn.datasets import fetch_lfw_people
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

faces = fetch_lfw_people(min_faces_per_person=60)

X = faces.data
pca = PCA(150)
X_dr = pca.fit_transform(X)

X_inverse = pca.inverse_transform(X_dr)
fig, ax = plt.subplots(2, 10, figsize=(10, 2.5)
                       , subplot_kw={"xticks": [], "yticks": []}
                       )

# 原特征矩阵与新特征矩阵的可视化 对比
for i in range(10):
    ax[0, i].imshow(faces.images[i, :, :], cmap="binary_r")
    ax[1, i].imshow(X_inverse[i].reshape(62, 47), cmap="binary_r")
plt.show()

"""
可以明显看出，这两组数据可视化后，由降维后再通过inverse_transform转换回原维度的数据画出的图像和原数据画的图像大致相似
仅损失了无关紧要的信息，就能识别同一个人，PCA降低计算成本
"""
```

